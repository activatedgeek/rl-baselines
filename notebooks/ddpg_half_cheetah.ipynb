{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG on Half Cheetah\n",
    "\n",
    "In this example we will see how to train a Deep deterministic policy gradiant (DDPG) agent using `torchrl`. See [Documentation](https://torchrl.sanyamkapoor.com/) for an introduction to *TorchRL* and installation instructions.\n",
    "\n",
    "This notebook requires mujoco-py. See [this](https://github.com/openai/mujoco-py) for installation instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchrl import registry\n",
    "from torchrl import utils\n",
    "from torchrl.problems import base_hparams, DDPGProblem\n",
    "from torchrl.agents import BaseDDPGAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a pre-built version of the DDPG agent from *TorchRL* library to initialize a `Problem`. This `Problem` class is also based on a pre-built version from the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPGHalfCheetah(DDPGProblem):\n",
    "  def init_agent(self):\n",
    "    observation_space, action_space = utils.get_gym_spaces(self.runner.make_env)\n",
    "\n",
    "    agent = BaseDDPGAgent(\n",
    "        observation_space,\n",
    "        action_space,\n",
    "        actor_lr=self.hparams.actor_lr,\n",
    "        critic_lr=self.hparams.critic_lr,\n",
    "        gamma=self.hparams.gamma,\n",
    "        tau=self.hparams.tau)\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class requires us to extend the init_agent method. There is no restriction on the contents as long as it returns a valid BaseAgent.\n",
    "\n",
    "## Hyperparameter Specification\n",
    "\n",
    "We use the `HParams` object from the library to add custom properties. Again, arbitrary properties can be provided to such objects as long as they are consistently used within the previously specified `Problem` class (e.g. within the `init_agent` routine).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hparams_ddpg_half_cheetah():\n",
    "    params = base_hparams.base_ddpg()\n",
    "\n",
    "    params.env_id = 'HalfCheetah-v2'\n",
    "\n",
    "    params.num_processes = 16\n",
    "\n",
    "    params.rollout_steps = 1\n",
    "    params.max_episode_steps = 500\n",
    "    params.num_total_steps = int(2e6)\n",
    "\n",
    "    params.gamma = 0.99\n",
    "    params.buffer_size = int(1e6)\n",
    "\n",
    "    params.batch_size = 128\n",
    "    params.tau = 1e-2\n",
    "    params.actor_lr = 1e-4\n",
    "    params.critic_lr = 1e-3\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Problem Instance\n",
    "\n",
    "We use GPUs if available and some basic arguments, most importantly the seed. Make sure to run using different seeds.\n",
    "\n",
    "**NOTE**: We use `argparse.Namespace` class as the argument to the `Problem` class which explains the type cast. If interested, track this issue [here](https://github.com/activatedgeek/torchrl/issues/61)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "args=dict(\n",
    "    seed=1,\n",
    "    log_interval=1000,\n",
    "    eval_interval=1000,\n",
    "    num_eval=1,\n",
    ")\n",
    "\n",
    "ddpg_half_cheetah = DDPGHalfCheetah(\n",
    "    hparams_ddpg_half_cheetah(),\n",
    "    argparse.Namespace(**args),\n",
    "    None, # Disable logging\n",
    "    device=device,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the DDPG Agent\n",
    "\n",
    "Calling the `run()` routine allows us to execute training. Note that for now we have disabled logging by keeping `log_dir=None` in the above instatiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [30:41<00:00, 67.86epochs/s] \n"
     ]
    }
   ],
   "source": [
    "ddpg_half_cheetah.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.08 s, sys: 1.29 s, total: 7.36 s\n",
      "Wall time: 8.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ddpg_half_cheetah.agent.train(False)\n",
    "\n",
    "eval_runner = ddpg_half_cheetah.make_runner(n_envs=10)\n",
    "eval_rewards = []\n",
    "for _ in range(100 // ddpg_half_cheetah.runner.n_envs):\n",
    "  eval_history = eval_runner.rollout(ddpg_half_cheetah.agent)\n",
    "  for i in range(ddpg_half_cheetah.runner.n_envs):\n",
    "    _, _, reward_history, _, _ = eval_history[0]\n",
    "    eval_rewards.append(np.sum(reward_history, axis=0))\n",
    "eval_runner.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 672.4418830774515 +/- 36.763124177817204\n"
     ]
    }
   ],
   "source": [
    "avg_reward, std_reward = np.average(eval_rewards), np.std(eval_rewards)\n",
    "print('Reward: {} +/- {}'.format(avg_reward, std_reward))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
